{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.xarray.dev/en/stable/_static/dataset-diagram-logo.png\" align=\"right\" width=\"30%\">\n",
    "\n",
    "# Parallel computing with Dask\n",
    "\n",
    "This notebook demonstrates one of Xarray's most powerful features: the ability\n",
    "to wrap [dask arrays](https://docs.dask.org/en/stable/array.html) and allow users to seamlessly execute analysis code in\n",
    "parallel.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. Xarray DataArrays and Datasets are \"dask collections\" i.e. you can execute\n",
    "   top-level dask functions such as `dask.visualize(xarray_object)`\n",
    "2. Learn that all xarray built-in operations can transparently use dask\n",
    "\n",
    "\n",
    "**Important:** *Using Dask does not always make your computations run faster!* Performance will depend on the computational infrastructure you're using (for example, how many CPU cores), how the data you're working with is structured and stored, and the algorithms and code you're running. Be sure to review the [Dask best-practices](https://docs.dask.org/en/stable/best-practices.html) if you're new to Dask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='readwrite'></a>\n",
    "\n",
    "## Reading data\n",
    "\n",
    "The `chunks` argument to both `open_dataset` and `open_mfdataset` allow you to\n",
    "read datasets as dask arrays. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.tutorial.open_dataset(\n",
    "    \"air_temperature\",\n",
    "    chunks={  # this tells xarray to open the dataset as a dask array\n",
    "        \"lat\": 25,\n",
    "        \"lon\": 25,\n",
    "        \"time\": -1,\n",
    "    },\n",
    ")\n",
    "ds.air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representation (\"repr\" in Python parlance) for the `air` DataArray shows the very nice HTML dask array repr. You can access the underlying chunk sizes using `.chunks`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: All variables in a `Dataset` need _not_ have the same chunk size along\n",
    "common dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='compute'></a>\n",
    "\n",
    "## lazy computation \n",
    "\n",
    "Xarray seamlessly wraps dask so all computation is deferred until explicitly\n",
    "requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = ds.air.mean(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask actually constructs a graph of the required computation. Here it's pretty simple: The full array is subdivided into 3 arrays. Dask will load each of these subarrays in a separate thread using the default [single-machine scheduling](https://docs.dask.org/en/stable/scheduling.html). You can visualize dask 'task graphs' which represent the requested computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.data.visualize(optimize_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting concrete values from dask arrays\n",
    "\n",
    "At some point, you will want to actually get concrete values (_usually_ a numpy array) from dask.\n",
    "\n",
    "There are two ways to compute values on dask arrays.\n",
    "\n",
    "1. `.compute()` returns an xarray object\n",
    "2. `.load()` replaces the dask array in the xarray object with a numpy array.\n",
    "   This is equivalent to `ds = ds.compute()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your data volumes grow and algorithms get more complex it can be hard to print out task graph representations and understand what Dask is doing behind the scenes. Luckily, you can use Dask's 'Distributed' scheduler to get very useful diagnotisic information.\n",
    "\n",
    "First let's set up a `LocalCluster` using [dask.distributed](https://distributed.dask.org/).\n",
    "\n",
    "You can use any kind of Dask cluster. This step is completely independent of\n",
    "xarray. While not strictly necessary, the dashboard provides a nice learning\n",
    "tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# This piece of code is just for a correct dashboard link mybinder.org or other JupyterHub demos\n",
    "import dask\n",
    "import os\n",
    "\n",
    "if os.environ.get('JUPYTERHUB_USER'):\n",
    "    dask.config.set(**{\"distributed.dashboard.link\": \"/user/{JUPYTERHUB_USER}/proxy/{port}/status\"})\n",
    "\n",
    "client = Client(local_directory='/tmp')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ Click the Dashboard link above. \n",
    "\n",
    "👈 Or click the \"Search\" 🔍 button in the [dask-labextension](https://github.com/dask/dask-labextension) dashboard.\n",
    "\n",
    "NOTE: if using the dask-labextension, you should disable the 'Simple' JupyterLab interface (`View -> Simple Interface`), so that you can drag and rearrange whichever dashboards you want. The `Workers` and `Task Stream` are good to make sure the dashboard is working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array\n",
    "\n",
    "dask.array.ones((1000, 4), chunks=(2, 1)).compute()  # should see activity in dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining a DataArray with dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our xarray DataSet, in addition to computing the mean, other operations such as indexing will automatically use whichever Dask Cluster we are connected to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.isel(lon=1, lat=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and more complicated operations...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = ds.air.rolling(time=5).mean().isel(lon=1, lat=20)  # no activity on dashboard\n",
    "timeseries  # contains dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = ds.air.rolling(time=5).mean()  # no activity on dashboard\n",
    "timeseries  # contains dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = mean.compute()  # activity on dashboard\n",
    "computed  # has real numpy values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `mean` still contains a dask array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we call `.load()`, `mean` will now contain a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that again...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** `.persist()` loads the values into distributed RAM. This is useful if\n",
    "you will be repeatedly using a dataset for computation but it is too large to\n",
    "load into local memory. You will see a persistent task on the dashboard.\n",
    "\n",
    "See https://docs.dask.org/en/latest/api.html#dask.persist for more\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting underlying data: `.values` vs `.data`\n",
    "\n",
    "There are two ways to pull out the underlying data in an xarray object.\n",
    "\n",
    "1. `.values` will always return a NumPy array. For dask-backed xarray objects,\n",
    "   this means that compute will always be called\n",
    "2. `.data` will return a Dask array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray data structures are first-class dask collections.\n",
    "\n",
    "This means you can do things like `dask.compute(xarray_object)`,\n",
    "`dask.visualize(xarray_object)`, `dask.persist(xarray_object)`. This works for\n",
    "both DataArrays and Datasets\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Visualize the task graph for a few different computations on ds.air!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Gracefully shutdown our connection to the Dask cluster. This becomes more important when you are running on large HPC or Cloud servers rather than a laptop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
